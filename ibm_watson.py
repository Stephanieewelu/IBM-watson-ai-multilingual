# -*- coding: utf-8 -*-
"""IBM Watson.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GYYMf4vW31wWe5Yg8wTxJWZKpufNHDDW
"""

!pip install fastapi uvicorn

!curl -X POST 'https://iam.cloud.ibm.com/identity/token' \
  -H 'Content-Type: application/x-www-form-urlencoded' \
  -d 'grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey=NNFdMnmNWYNw1bx4MuHOIAnmWABci3-5aZ_wZXmyrIYw'

from fastapi import FastAPI, WebSocket
from ibm_watson import SpeechToTextV1, TextToSpeechV1
from ibm_cloud_sdk_core.authenticators import IAMAuthenticator
import requests
import json
import asyncio
import base64
import io
import os
import logging

app = FastAPI()

# IBM Watson API Credentials (Using your provided API key, assuming US-South region)
IBM_API_KEY = "NNFdMnmNWYNw1bx4MuHOIAnmWABci3-5aZ_wZXmyrIYw"

# Service URLs (Defaulting to US-South; adjust if your services are in a different region like EU-GB)
IBM_URL_STT = "https://api.us-south.speech-to-text.watson.cloud.ibm.com"
IBM_URL_TTS = "https://api.us-south.text-to-speech.watson.cloud.ibm.com"

# watsonx.ai Granite Endpoint (US-South)
WATSONX_API_URL = "https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2023-05-29"
PROJECT_ID = "8323eb5c-db81-438a-8ae1-1696d9550cbf"
MODEL_ID = "ibm/granite-20b-multilingual"

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Initialize IBM Watson Services
stt_authenticator = IAMAuthenticator(IBM_API_KEY)
stt = SpeechToTextV1(authenticator=stt_authenticator)
stt.set_service_url(IBM_URL_STT)

tts_authenticator = IAMAuthenticator(IBM_API_KEY)
tts = TextToSpeechV1(authenticator=tts_authenticator)
tts.set_service_url(IBM_URL_TTS)

# Function to get OAuth token with detailed logging
def get_access_token(api_key):
    token_url = "https://iam.cloud.ibm.com/identity/token"
    headers = {"Content-Type": "application/x-www-form-urlencoded"}
    data = {
        "grant_type": "urn:ibm:params:oauth:grant-type:apikey",
        "apikey": api_key
    }
    response = requests.post(token_url, headers=headers, data=data)
    if response.status_code != 200:
        logger.error("Failed to get access token: Status %d, Response: %s", response.status_code, response.text)
        raise Exception(f"Failed to get access token: {response.text}")
    token = response.json()["access_token"]
    logger.info("Access token generated: %s...", token[:20])
    return token

# Get access token
access_token = get_access_token(IBM_API_KEY)

@app.websocket("/ws")
async def websocket_endpoint(ws: WebSocket):
    await ws.accept()
    logger.info("WebSocket connection established!")

    try:
        while True:
            data = await ws.receive_text()
            message_data = json.loads(data)

            # Step 1: Transcribe Speech (Assuming message_data contains audio data as path)
            audio_file_path = message_data.get("audio_path", None)
            if not audio_file_path or not os.path.exists(audio_file_path):
                logger.warning("No valid audio_path provided or file not found")
                await ws.send_json({"error": "No valid audio path provided or file not found"})
                continue

            # Ensure audio is in WAV format (16kHz, mono, PCM 16-bit) for Watson STT
            try:
                # Check if file is M4A; convert to WAV if needed
                if audio_file_path.lower().endswith(".m4a"):
                    output_wav = audio_file_path.replace(".m4a", ".wav")
                    os.system(f"ffmpeg -i {audio_file_path} -acodec pcm_s16le -ac 1 -ar 16000 {output_wav}")
                    audio_file_path = output_wav
                logger.info(f"Processing audio file: {audio_file_path}")

                with open(audio_file_path, "rb") as audio_file:
                    stt_result = stt.recognize(
                        audio=audio_file,
                        content_type="audio/wav",
                        model="es-ES_BroadbandModel",  # Optimized for Spanish
                        timestamps=False,
                        word_confidence=False
                    ).get_result()
                transcribed_text = stt_result["results"][0]["alternatives"][0]["transcript"]
                logger.info(f"Transcribed text: '{transcribed_text}'")
            except Exception as e:
                logger.error(f"Speech-to-Text failed: {e}")
                await ws.send_json({"error": f"Transcription failed: {str(e)}"})
                continue

            # Step 2: Process with Granite Multilingual Model
            try:
                headers = {
                    "Accept": "application/json",
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {access_token}"
                }
                body = {
                    "input": (
                        f"<|system|>\n"
                        f"You are Granite Chat, an AI language model developed by IBM. You are a cautious assistant. You carefully follow instructions. You are helpful and harmless and you follow ethical guidelines and promote positive behavior. You always respond to greetings (for example, hi, hello, g'day, morning, afternoon, evening, night, what's up, nice to meet you, sup, etc) with \"Hello! I am Granite Chat, created by IBM. How can I help you today?\". Please do not say anything else and do not start a conversation.\n"
                        f"<|assistant|>\n"
                        f"Translate the following text from es to en:\n"
                        f"'{transcribed_text}'\n\n"
                        f"Then, provide a polite business response in en."
                    ),
                    "parameters": {
                        "decoding_method": "greedy",
                        "max_new_tokens": 900,
                        "min_new_tokens": 0,
                        "repetition_penalty": 1.05
                    },
                    "model_id": MODEL_ID,
                    "project_id": PROJECT_ID
                }

                response = requests.post(WATSONX_API_URL, headers=headers, json=body)
                if response.status_code != 200:
                    raise Exception(f"Non-200 response from Granite: {response.text}")

                data = response.json()
                generated_text = data.get("results", [{}])[0].get("generated_text", "")
                parts = generated_text.split('\n')
                translated_text = parts[0].strip() if parts else generated_text
                business_response = parts[1].strip() if len(parts) > 1 else "Thank you for your message. How else can I assist you?"
                logger.info(f"Translated text (en): '{translated_text}'")
                logger.info(f"Business response: '{business_response}'")
            except Exception as e:
                logger.error(f"Granite processing failed: {e}")
                # Fallback to Watson Language Translator
                try:
                    translation_result = translator.translate(
                        text=transcribed_text,
                        model_id="es-en"  # Spanish to English
                    ).get_result()
                    translated_text = translation_result["translations"][0]["translation"]
                    business_response = f"{translated_text}. Thank you for your message. How else can I assist you?"
                    logger.info(f"Fallback translated text (en): '{translated_text}'")
                    logger.info(f"Fallback business response: '{business_response}'")
                except Exception as e:
                    logger.error(f"Watson translation failed: {e}")
                    translated_text = "Translation failed"
                    business_response = "Sorry, I couldnâ€™t process your request. How else can I assist you?"
                    await ws.send_json({"error": f"Translation failed: {str(e)}"})
                    continue

            # Step 3: Convert to Speech and Save Audio
            try:
                tts_response = tts.synthesize(
                    text=business_response,
                    voice="en-US_MichaelV3Voice",  # English voice for response
                    accept="audio/wav"
                ).get_result()
                audio_data = tts_response.content
                audio_base64 = base64.b64encode(audio_data).decode("utf-8")  # Convert to base64 for WebSocket
                # Save audio for manual playback (avoiding sounddevice dependency)
                audio_filename = "response_audio.wav"
                with open(audio_filename, "wb") as f:
                    f.write(audio_data)
                logger.info(f"TTS audio generated and saved as '{audio_filename}'")
            except Exception as e:
                logger.error(f"TTS generation failed: {e}")
                await ws.send_json({"error": f"Text-to-Speech failed: {str(e)}"})
                continue

            # Send Response
            response_data = {
                "original_text": transcribed_text,
                "translated_text": translated_text,
                "business_response": business_response,
                "audio_base64": audio_base64,
                "audio_file": "response_audio.wav"  # Path for manual playback
            }
            await ws.send_json(response_data)

    except Exception as e:
        logger.error(f"WebSocket error: {e}")
        await ws.close()

if __name__ == "__main__":
    import uvicorn
    config = uvicorn.Config(app, host="0.0.0.0", port=8000, log_level="info")
    server = uvicorn.Server(config)

    if asyncio.get_event_loop().is_running():
        asyncio.create_task(server.serve())
    else:
        asyncio.run(server.serve())